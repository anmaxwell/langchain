{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926accc7-7cf5-4259-b8ce-136ac936a2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Project to read in all tours from explore.co.uk\n",
    "# Use this output to be able to recommend tours given a request from a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d077aa5-f32a-433a-a124-5fd7a85f90b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the llm\n",
    "#> ollama run llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d613f135-7394-49de-a94e-56cc822b6f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58f8c21-5e47-4f9d-bd37-30264ba36d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import html5lib\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk, string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import scipy\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "import transformers\n",
    "import numpy\n",
    "\n",
    "nltk.download('punkt') # if necessary..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebb9b7f-e1fc-4825-ab85-4d5f48354c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define functions to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae45eb72-5fc1-4f15-8521-70d8eb54a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for calculating similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6736f6-7a6c-4ef3-b8db-c02114f144cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(query, document):\n",
    "    query = query.lower().split(\" \")\n",
    "    document = document.lower().split(\" \")\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    union = set(query).union(set(document))\n",
    "    return len(intersection)/len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09a8758-4f38-44db-98e9-9be64f5c176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "'''remove punctuation, lowercase, stem'''\n",
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english')\n",
    "\n",
    "def cosine_sim(text1, text2):\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    return ((tfidf * tfidf.T).A)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea7a33-1c27-4a2f-8cc2-aa38cbf8a794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensimy(text1, corpus_of_documents):\n",
    "    gen_docs = [[w.lower() for w in word_tokenize(text)]\n",
    "        for text in corpus_of_documents]\n",
    "    dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "    corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "    tf_idf = gensim.models.TfidfModel(corpus)\n",
    "    sims = gensim.similarities.Similarity('workdir/',tf_idf[corpus], num_features=len(dictionary))\n",
    "    query_doc = [w.lower() for w in word_tokenize(text1)]\n",
    "    query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "    query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "    return(sims[query_doc_tf_idf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e20298-8185-4232-aec2-fe31b72b7c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return similarities of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062c881a-91b6-4da6-8335-39de9de4c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_response(sim_func, query, corpus):\n",
    "    similarities = []\n",
    "    for doc in corpus:\n",
    "        similarity = sim_func(user_input, doc)\n",
    "        similarities.append(similarity)\n",
    "        tour_id = similarities.index(max(similarities))\n",
    "    return tour_id, corpus_of_documents[similarities.index(max(similarities))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5495bb0a-2021-4ada-8184-4a7af62b6f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in a list of urls to scrape the tour details from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32922d41-61e6-42b7-9aec-ae1e7ac3f204",
   "metadata": {},
   "outputs": [],
   "source": [
    "tour_urls = ['https://www.explore.co.uk/holidays/machu-picchu-trek',\n",
    "             'https://www.explore.co.uk/holidays/vietnam-historic-tour',\n",
    "             'https://www.explore.co.uk/holidays/cycling-holiday-morocco',\n",
    "             'https://www.explore.co.uk/holidays/taste-of-japan-tokyo-kyoto-osaka',\n",
    "             'https://www.explore.co.uk/holidays/india-tiger-safari',\n",
    "             'https://www.explore.co.uk/holidays/family-costa-rica-highlights',\n",
    "             'https://www.explore.co.uk/holidays/central-american-highlights',\n",
    "             'https://www.explore.co.uk/holidays/costa-rica-wildlife-tour',\n",
    "             'https://www.explore.co.uk/holidays/vietnam-adventure-tour',\n",
    "             'https://www.explore.co.uk/holidays/vietnam-walking-holiday',\n",
    "             'https://www.explore.co.uk/holidays/peru-amazon-extension']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf17100-dc79-4c23-8008-aaff5812a09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the list and get the itinerary for each tour with the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e019bcb3-1f28-4119-b577-064d4252a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = []\n",
    "tours = []\n",
    "for index, url in enumerate(tour_urls):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html5lib')\n",
    "\n",
    "    tours.append(soup.title.get_text().replace('\\n', ' ').replace('\\t', ''))\n",
    "    table = soup.find('div', attrs = {'id':'itinerary'})\n",
    "\n",
    "    itinerary = []  # a list to store quotes\n",
    "    for row in table.findAll('div', attrs = {'class':'pr-i-desc'}): \n",
    "        itinerary.append(row.p.get_text())\n",
    "\n",
    "    contents.append(itinerary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c61b8b-e98a-4fd1-84f2-7cbe5433ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcfd50a-1fe6-4408-b951-6b77c83ac628",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_of_documents = []\n",
    "for item in contents:\n",
    "    full_details = ' '.join(item)\n",
    "    corpus_of_documents.append(full_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cff3a36-0a28-466a-ac86-4ab2712bd32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b58a0b8-b97a-47a6-b823-64a5e9a041f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I'd like to visit South America and visit Machu Picchu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec29992-78c4-417d-98b3-15a66c116a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the relevant document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8038901a-eebe-48ef-aadf-94e839b68ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_tour, relevant_document = return_response(jaccard_similarity, user_input, corpus_of_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28eabe-e51e-4d01-89e4-0d4ee80f37d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_tour, relevant_document = return_response(cosine_sim, user_input, corpus_of_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11f9e50-1fba-4078-b136-8a3770dcf37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_tour, relevant_document = return_response(gensimy, user_input, corpus_of_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f82c6b-1f3b-4493-9964-73ee6eefaf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43e9813-6d1c-402c-9612-ecdb2d534e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a bot that makes recommendations for holidays. You answer with facts, highlighting pros and cons.\n",
    "This is the recommended holiday: {relevant_document}\n",
    "The user input is: {user_input}\n",
    "Compile a recommendation to the user based on the recommended activity and the user input.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf81b9-61c8-481e-89b2-0654b8c6be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup llama3\n",
    "url = 'http://localhost:11434/api/generate'\n",
    "data = {\n",
    "    \"model\": \"llama3\",\n",
    "    \"prompt\": prompt.format(user_input=user_input, relevant_document=relevant_document)\n",
    "}\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.post(url, data=json.dumps(data), headers=headers, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c5b3cd-1882-4258-921e-37b2ad333c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate and return the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa648c9d-82db-41be-ace3-1b5e58778d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_response = []\n",
    "try:\n",
    "    count = 0\n",
    "    for line in response.iter_lines():\n",
    "        # filter out keep-alive new lines\n",
    "        # count += 1\n",
    "        # if count % 5== 0:\n",
    "        #     print(decoded_line['response']) # print every fifth token\n",
    "        if line:\n",
    "            decoded_line = json.loads(line.decode('utf-8'))\n",
    "            \n",
    "            full_response.append(decoded_line['response'])\n",
    "finally:\n",
    "    response.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478d2e10-76f8-4a23-9588-e029a6e7f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tours[relevant_tour], ''.join(full_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f9ddd-a0ed-4b25-9599-e4dcfe5b045f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dca1c6-18ee-4ce7-b9a3-145e7a84b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_func1(query, corpus_of_documents):\n",
    "    query = query.lower().split(\" \")\n",
    "    sims = []\n",
    "    for document in corpus_of_documents:\n",
    "        document = document.lower().split(\" \")\n",
    "        intersection = set(query).intersection(set(document))\n",
    "        union = set(query).union(set(document))\n",
    "        sims.append(len(intersection)/len(union))\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d818d62e-79cb-4661-a973-e39c1ef414bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_func2(query, corpus_of_documents):\n",
    "    gen_docs = [[w.lower() for w in word_tokenize(text)]\n",
    "        for text in corpus_of_documents]\n",
    "    dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "    corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "    tf_idf = gensim.models.TfidfModel(corpus)\n",
    "    sims = gensim.similarities.Similarity('workdir/',tf_idf[corpus], num_features=len(dictionary))\n",
    "    query_doc = [w.lower() for w in word_tokenize(query)]\n",
    "    query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "    query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "    return(sims[query_doc_tf_idf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e41d70-c534-4a7e-aa3e-7c557dc9409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_func3(query, corpus_of_documents):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    sims = []\n",
    "    for document in corpus_of_documents:\n",
    "        query = nlp(query)\n",
    "        document = nlp(document)\n",
    "        sims.append(query.similarity(document))\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c186868e-bccd-4324-8058-ce05ddc280dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_func4(query, corpus_of_documents):\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "    def stem_tokens(tokens):\n",
    "        return [stemmer.stem(item) for item in tokens]\n",
    "    \n",
    "    '''remove punctuation, lowercase, stem'''\n",
    "    def normalize(text):\n",
    "        return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english')\n",
    "\n",
    "    tfidf = vectorizer.fit_transform([query, corpus_of_documents])\n",
    "    return ((tfidf * tfidf.T).A)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1138a-cde1-4367-9309-a18df5386abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_func1(user_input, corpus_of_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e13418-cf03-4d8e-a8e6-15e8a4b6f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_func2(user_input, corpus_of_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0685c-6574-47ff-baf6-73db7b6efde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_func3(user_input, corpus_of_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db3f6f5-b860-4f59-be8d-f1fdeb13682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = corpus_of_documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7bcb62-7dff-4539-aeb8-5577ddd23e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = nlp(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbae863-e29f-41db-8039-6f39003d330e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051d539f-7b98-4af2-a0aa-95e5164ffa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close llama3\n",
    "#> /bye"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
